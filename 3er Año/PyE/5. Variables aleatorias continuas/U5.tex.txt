\documentclass{report}
\usepackage[utf8]{inputenc}
\usepackage{vmargin}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{titlesec}
\titleformat{\chapter}
  {\normalfont\LARGE\bfseries}{\thechapter}{1em}{}
\titlespacing*{\chapter}{0pt}{3.5ex plus 1ex minus .2ex}{2.3ex plus .2ex}
\graphicspath{ {images/} }
\setpapersize{A4}
\setmargins{2.5cm}       % margen izquierdo
{1.5cm}                        % margen superior
{16.5cm}                      % anchura del texto
{23.42cm}                    % altura del texto
{10pt}                           % altura de los encabezados
{1cm}                           % espacio entre el texto y los encabezados
{0pt}                             % altura del pie de página
{2cm}           
\begin{document}


\tableofcontents



\begin{titlepage}
\centering
{\bfseries\LARGE Universidad Nacional de Rosario \par}
\vspace{0,5cm}
{\scshape\Large Facultad de Ciencias Exactas, Ingeniería y Agrimensura \par}
\vspace{2cm}
{\scshape\Huge Probabilidad y Estadística\par}
\vspace{3cm}
{\itshape\Huge Unidad 5 \par}
\vfill
{\Large Autor del resumen:\par}
\vspace{1 cm}
{\Large Charles Chaplin\par}
\vfill
{\Large Julio 2020 \par}
\end{titlepage}



\newpage



\chapter{Variables aleatorias continuas}

\vspace{1,5cm}
\section{Variable aleatoria continua}

{Supongamos que el recorrido de X está formado por un gran número finito de valores, por ejemplo, todos los valores x en el intervalo $[0,1]$, de la forma 0,0.01,0.02,...,0.98,0.99,1. Con cada uno de estos valores asociados a un número no negativo p($x_i$) = P(X=$x_i$), i = 1,2,..., cuya suma es igual a 1. \\ 

Matemáticamente podría ser más sencillo idealizar la anterior descripción probabilística de X al suponer que X puede tomar todos los valores posbiles, $[0,1]$. Si hacemos esto, ¿Qué le sucede a las probabilidades puntuales $p(x_i)$? Puesto que los valores posibles de X no son contables, en realidad no se puede hablar de un i-ésimo valor de X, y por tanto, p($x_i$) pierde significado.  \\ 

Lo que haremos es sustituir la función p, definida sólo para $x_1,x_2,...,$ por una función $f$ definida (en el contexto presente) para todos los valores de x, $0 \leq x \leq 1$. Procederemos formalmente
como sigue.}

\vspace{1cm}

{\bf Definición.} {Se dice que X es una {\bf variable aleatoria continua} si existe una función f, llamada {\bf función de densidad de probabilidad} (fdp) de X, que satisfaga: }
\vspace{0,5cm}
\begin{itemize}
    \item [a)] $\forall_x \ f(x) > 0$ 
    \item [b)] $\int_{-\infty}^{+\infty} f(x) \ dx = 1$
    \item [c)] $\forall_{a,b},   -\infty < a < b < \infty$, $P(a \leq X \leq b) = \int_{a}^{b} f(x) \ dx$
\end{itemize}
\vspace{1cm}

{\bf Observaciones}
\begin{itemize}
    \item [a)] La existencia estipulada de una fdp es un método matemático que tiene una base intuitiva considerable y hace más sencillos nuestros cálculos. En relación con esto, de nuevo se debe señalar que cuando suponemos que X es una variable aleatoria continua, estamos considerando la descripción idealizada de S. 
    
    \item [b)] $P(c < X < d)$ representa el área bajo la gráfica de la fdp f entre x = c y x = d. 
    
    \item [c)] Una consecuencia de la descripción probabilística de X para cualquier valor específico de X, por ejemplo $x_0$, es que tenemos P(X = $x_0$) = 0, puesto que P(X = $x_0$) = $\int _{x_0}^{x_0}f(x)dx$ = 0. Si permitimos que X tome todos los valores en un intervalo, entonces la probabilidad 0 no es equivalente con la imposibilidad. Cuando indicamos esto en un lenguaje matemático preciso, decimos que el evento tiene “probabilidad 0”. Por tanto, si X es una variable aleatoria continua tenemos
\end{itemize}

\begin{center}
    $P(c\leq X \leq d)$, $P(c\leq X < d)$, $P(c< X \leq d)$ y $P(c< X < d)$
\end{center}

\begin{itemize}
    \item [d)] Si una función $f^*(x)$ satisface que $\forall_x \ f^*(x) \geq 0$, y $\int _{-\infty}^{+\infty}f^*(x)dx = K$, $f^*$ no es una fdp pero   
\end{itemize}

\begin{center}
    $f(x) = \frac{f^*}{K}$,
\end{center}

\begin{itemize}
    \item [] si lo es.
\end{itemize}
\newpage
\begin{itemize}
    \item [f)] Si X sólo toma valores en un intervalo [a,b], simplemente podemos establecer $f(x) = 0$ para todo x $\notin$ [a,b]. Por tanto, la fdp está definida para todos los valores reales de x, y debemos exigir que $_{-\infty}^{+\infty}f(x)dx = 1$ . Cuando quiera que la fdp se especifique sólo para ciertos valores de x, supondremos que es cero para cualquier otro.
    
    \item [g)] $f(x)$ no representa la probabilidad de nada. Sólo cuando la función se integra entre dos límites produce una probabilidad. Si $\Delta$x es pequeña, $f(x) \Delta x$ es aproximadamente igual a $P(x \leq X \leq x +\Delta x)$
    
    \item [h)] En este caso la fdp es inducida en $R_x$ por las probabilidades asociadas con eventos en S. Por esto, cuando escribimos $P(c < X < d)$, queremos decir $P(c < X(s) < d)$, que a su vez es equivalente a $P[s| c < X(s) < d]$. Por lo tanto existe una fdp definida en $R_x$ tal que:
\end{itemize}

\begin{center}
    $P[s\in S|c < X(s) < d] = \int_c^df(x)dx$
\end{center}

\begin{itemize}
    \item [] Se eliminará la naturaleza funcional de X y por lo tanto estaremos interesados  sólo en $R_x$ y la fdp $f$.
\end{itemize}
\vspace{1cm}

\begin{center}
    \bf Ejemplos págs. 88-90
\end{center}
\vspace{1cm}

\section{Función de distribución acumulada}
\vspace{0,5cm}
{\bf Definición.} {Sea X una variable aleatoria, discreta o continua. Definimos que F es la {\bf función de distribución acumulativa} de la variable aleatoria X (abreviada fda) como F(x) = $P(X \leq x)$}

\vspace{1cm}

{\bf Teorema.}
\begin{itemize}
    \item [a)] Si X es una variable aleatoria discreta
        \subitem \[F(x) = \sum_jp(x_j)\]
        \subitem donde cada indice j corresponde a un $x_j \leq x$
    
    \item [b)] Si X es una variable aleatoria continua con fdp f
        \subitem \[F(x) = \int_{-\infty}^x f(s) ds, \ \ s \in R_x\]
\end{itemize}
\vspace{1,3cm}
\begin{center}
    \bf Ejemplos págs 91-92
\end{center}
\vspace{1cm}
\newpage

{\bf Teorema.}

\begin{itemize}
    \item [a)] La función F es no decreciente. Esto es  si $ x_1 < x_2 \Rightarrow F(x_1) < F(x_2)$
    
    \item [b)] $lim_{x \rightarrow -\infty}F(x) = 0$ y $lim_{x \rightarrow \infty}F(x) = 1$ (también denotados como F($-\infty$) y F($\infty$)) 
    
    \item \subitem \bf Demostración pág 92
\end{itemize}

\vspace{0,5cm}

{La función de distribución acumulativa es importante por varias razones. Esto es particularmente cierto cuando tratamos con una variable aleatoria continua, porque en este caso no podemos estudiar la conducta probabilística de X al calcular P(X = x). Esa probabilidad siempre es igual a cero en el caso continuo. Sin embargo, podemos inquirir acerca de P(X $<$ z) y, como lo demostramos en el próximo teorema, obtener la fdp de X. }
\vspace{1cm}

{\bf Teorema}

\begin{itemize}
    \item [a)] Sea F la fda de una variable aleatoria continua con fdp f. Luego,
        \subitem \[f(x) = \frac{d}{dx} F(X),\]
        \subitem para toda x en la cual F es diferenciable.
    \item [b)] Sea X una variable aleatoria discreta con valores posibles $x_1,x_2,...,$ y supongamos que es posible rotular esos valores de modo que $x_1<x_2<...$. Sea F la fda de X. Entonces,
        \subitem \[p(x_j) = P(X=x_j) = F(x_j) - F(x_{j-1})\]
        \subitem \bf Demostración pág 93-94 (recomendado leer)
\end{itemize}
\vspace{2cm}
\begin{center}
    \bf Ejemplo pág 94
\end{center}
\vspace{2cm}

{\bf Características de la fda}
\begin{itemize}
    \item [a)] Si X es una variable aleatoria discreta con un número finito de valores posibles, la gráfica de la fda F será la de una función escalonada
    
    \item [b)] Si X es una variable aleatoria continua, F será una función continua para toda x. 
    
    \item [c)]  La fda F está definida para todos los valores de x, lo cual es una razón importante para considerarla.
\end{itemize}


\newpage

\section{Distribuciones mixtas (pág 95)}

\vspace{1cm}

\section{Variables aleatorias distribuidas uniformemente}
\vspace{0,5cm}


{\bf Definición.} {Supongamos que X es una variable aleatoria continua que toma todos los valores en el intervalo [a, b], donde ambos, a y b, son finitos. Si la fdp de X está dada por}

\vspace{0,3cm}
\begin{center}
    $f(x)= \left\{ \begin{array}{lcc}
             \frac{1}{b-a}  &   si  & a \leq x \leq b \\
             \\ 0 &  si & otro \ valor \\
             \end{array}
   \right.$
\end{center}
\vspace{0,3cm}

{decimos que X está {\bf distribuida uniformemente} en el intervalo [a,b]}

\vspace{1cm}

{\bf Observaciones}
\begin{itemize}
    \item [a)]  Una variable aleatoria distribuida uniformemente tiene una fdp que es una constante en el intervalo de definición. A fin de satisfacer la condición $\int_{-\infty}^\infty f(x) = 1$, esta constante debe ser igual al recíproco de la longitud del intervalo
    
    \item [b)] Para cualquier subintervalo [c, d], donde $a \leq c < d \leq b, P(c \leq X \leq d)$ es la misma para todos los subintervalos que tienen la misma longitud. Esto es, 
        \subitem \[P(c\leq X \leq d) = \int_c^d f(x)dx = \frac{d-c}{b-a}\]
        \subitem y así, solo depende de la longitud del intervalo y no de la ubicación.
        
    \item [c)]  Ahora podemos precisar la noción intuitiva de elegir un punto P al azar en un intervalo, por ejemplo [a, b]. Con esto sólo indicaremos que la coordenada x del punto elegido, por ejemplo X, está distribuida uniformemente en [a, b]. 
\end{itemize}
\vspace{1cm}
\begin{center}
    \bf Ejemplos págs 96-97 (fda en ejemplo 4.19)
\end{center}
\vspace{2cm}
{\bf Valores característicos}
\begin{itemize}
    \item [] $E(X) = \int_{-\infty}^{\infty}x f(x) dx = \frac{b+a}{2}$
    \item [] $V(X) = \int_{-\infty}^{\infty} (x-E(X))^2 f(x) dx = \frac{(b-a)^2}{12}$
\end{itemize}

\newpage

\section{La distribución exponencial}
\vspace{1,5cm}

{\bf Definición.} {Se dice que una variable aleatoria continua X que toma todos los valores no negativos tiene una distribucion exponencial con parámetro $\alpha > 0$ si su fdp está dada por} 
\vspace{0,3cm}
\begin{center}
    $f(x)= \left\{ \begin{array}{lcc}
             \alpha e^{-\alpha x}  &   si  & x > 0 \\
             \\ 0 &  si & otro \ valor \\
             \end{array}
   \right.$
\end{center}
\vspace{0,3cm}

{La distribución exponencial desempeña un papel importante en la
descripción de una gran clase de fenómenos, especialmente en el área de la teoría de la confiabilidad}
\vspace{1cm}

{\bf Propiedades de la distribución exponencial}
\vspace{0,5cm}
\begin{itemize}
    \item [a)] La fda F de la distribucion exponencial está dada por
\end{itemize}

\begin{center}
    $F(x) = \left\{ \begin{array}{lcc}
             1 - \alpha e^{-\alpha x}  &   si  & x \geq 0 \\
             \\ 0 &  si & otro \ valor \\
             \end{array}
   \right.$
\end{center}

\begin{itemize}
    \item [b)]  El valor esperado de X es:
\end{itemize}

\begin{center}
    $E(X) = \frac{1}{\alpha}$
\end{center}

\begin{itemize}
    \item [c)] La varianza de X es:
\end{itemize}

\begin{center}
    $V(X) = \frac{1}{\alpha ^2}$
\end{center}

\begin{itemize}
    \item [d)] Considerando para cualquier s, t $>$ 0, P(X $>$ s + t $|$ X $>$ s). Tenemos
\end{itemize}

\begin{center}
    $P(X > s + t | X > s) = \frac{P(X>s+t)}{P(X>s)} = \frac{e^{-\alpha(s+t)}}{e^{-\alpha s}} = e^{-\alpha t}$
\end{center}

\begin{itemize}
    \item [] Por lo que $P(X > s + t | X > s) = P(X>t)$
    \item []
    \subitem Así hemos demostrado que la distribución exponencial también tiene la propiedad de "no tener memoria" como la distribución geométrica. 
\end{itemize}
\vspace{2cm}
\begin{center}
    \bf Ejemplos págs 251-254
\end{center}

\newpage

\section{Distribución normal}
\vspace{1,5cm}

{Una de las variables aleatorias más notables es la siguiente.}
\vspace{1cm}

{\bf Definición.} {La variable aleatoria X, que toma todos los valores reales, $-\infty < x < \infty$, tiene una distribución normal (o gaussiana) si su fdp es de la forma}
\vspace{0,5cm}

\[f(x) = \frac{1}{\sqrt{2\pi}\sigma}exp\left( -\frac{1}{2}\left[\frac{x-\mu}{\sigma}\right]^2\right), \ \ -\infty < x < \infty\]
\vspace{0,5cm}

{Los parámetros $\sigma \ y \ \mu$ deben satisfacer las condiciones $-\infty < \mu < \infty, \ \sigma > 0$. Si una variable aleatoria continua X tiene una fdp de la forma descripta anteriormente, decimos que X es una distribución $X\sim N(\mu,\sigma^2)$. [Con frecuencia usamos la notación exp (t) para representar $e^t$.] }
\vspace{0,5cm}

{La distribución normal sirve como una aproximación excelente a una gran cantidad de distribuciones que tienen importancia práctica. Aún más, esta distribución tiene varias propiedades matemáticas apreciables que hacen posible deducir resultados teóricos notables.}

\vspace{2cm}

{\bf Propiedades de la distribución normal.}
\vspace{0,5cm}
\begin{itemize}
    \item [a)] $\forall_x \ f(x) > 0 \ y \int_{-\infty}^\infty f(x) dx = 1 $, es decir es una fdp legítima (demostración pág 240)
    \item [b)] La gráfica de esta f es {\bf simétrica} respecto a $\mu$. El parámetro $\sigma$ puede interpretarse en forma geométrica. Observemos que para $x = \mu$ la gráfica de f es cónciava hacia abajo. Cuando $x\rightarrow \pm \infty, f(x) \rightarrow 0$, asintóticamente. Puesto que $\forall_x, f(x) \geq 0$, esto significa que para grandes valores (en absoluto) de x, la gráfica de f es cóncava hacia arriba. El punto en el cual cambia la concavidad se llama {\bfpunto de inflexión} y se determina al resolver la ecuación f”(x) = 0. Cuando hacemos esto, encontramos que los puntos de inflexión ocurren en $x = \mu\pm\sigma $. Esto es, $\sigma$ unidades a la derecha y a la izquierda de $\mu$, la gráfica de f cambia de concavidad. Así, si $\sigma$ es relativamente grande, la gráfica de f tiende a ser “achatada”, mientras que si $\sigma$  es pequeña la gráfica de f tiende a ser muy “aguzada”. 
    
    \item [c)] $E(X) = \mu$ y $V(X) = \sigma ^2$. Así encontramos que los dos parámetros  $\mu$ y $\sigma^2$, que caracterizan la distribución normal son la esperanza y la varianza de X, respectivamente. Para decirlo con otras palabras si sabemos que X está distribuido normalmente, sólo sabemos que su distribución de probabilidades es de cierto tipo (o pertenece a cierta familia). Si además conocemos E(X) y V(X), la distribución de X está especificada por completo.
    
    \item [d)]  Si X tiene una distribución $N(0,1)$ decimos que X tiene una distribución normal estandarizada. Esto es, la fdp de X puede escribirse como \\ \[\varphi (x) = \frac{1}{\sqrt{2\phi}}e^{-\frac{x^2}{2}}\] 

\end{itemize}

\newpage

La importancia de la distribución normal estandarizada se debe al hecho de que esta tabulada. Cada vez que X tiene una distribución N($\mu,\sigma^2$) siempre podemos obtener la forma estandarizada tomando simplemente una función lineal de X, como lo indica el teorema siguiente.
\vspace{1cm}

{\bf Teorema.}{ Si X tiene la distribución N($\mu,\sigma^2$) y si Y = aX + b, entonces Y tiene la distribución N(a $\mu$ + b, $a^2\sigma^2$).} {\bf Dem. p. 244}
\vspace{1cm}

{\bf Corolario} {Si X tiene una distribución N($\mu,\sigma^2$) y si Y = $\frac{X-\mu}{\sigma}$, entonces Y tiene una distribución N(0,1).} {\bf Se aplica teorema anterior.}
\vspace{1cm}

\subsection{\bf Tabulacion de la distribución Normal}
\vspace{1cm}

{Sea $X\sim N(0,1)$, entonces}

\[P(a \leq X \leq b) = \frac{1}{\sqrt{2\pi}}\int_a^b e^{-x^2/2} dx.\]
\vspace{0,5cm}


{Esta integral no puede evaluarse por métodos ordinarios. (La dificultad proviene del hecho de que no podemos aplicar el TFC, puesto que no podemos encontrar una función cuya derivada sea igual a $e^{-x^2/2}$.) Sin embargo, los metodos de integracion numérica pueden usarse para evaluar integrales de la forma anterior, y de hecho P(X $\leq$ s) ha sido tabulado.\\
La fda de la distribución normal estandarizada se denotara consistentemente con $\Phi$.}
\vspace{0,3cm}

\[\Phi(s) = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^b e^{-x^2/2} dx.\]

\vspace{0,3cm}

{Podemos usar ahora la tabulacion de la funcion $\Phi$ con el objeto de evaluar $P(a \leq X \leq b)$, donde X tiene la distribucion estandarizada N(0,1), puesto que}
\vspace{0,1cm}

\[P(a \leq X \leq b) = \Phi(b) - \Phi(a).\]

{De esta definicion es evidente que $\Phi(-x) = 1-\Phi(x)$.\\ \\}
{La importancia particular de la tabulación anterior se debe al hecho de que si X tiene cualquier distribución normal $N(\mu,\sigma^2)$, la función tabulada $\Phi$ puede usarse para evaluar probabilidades asociadas con X. \\

Simplemente usamos el teorema anterior para observar que si $X\sim N(\mu,\sigma^2)$, entonces $ Y = \frac{X-\mu}{\sigma}$ tiene distribucion N(0,1). Por lo tanto }
\vspace{0,5cm}

\[P(a\leq X \leq b) = P\left(\frac{a-\mu}{\sigma}\leq Y \leq \frac{b-\mu}{\sigma}\right)\]

\[P(a\leq X \leq b) = \Phi \left(\frac{b-\mu}{\sigma}\right) - \Phi\left(\frac{a-\mu}{\sigma}\right) \]


\newpage

{Finalmente calculemos $P(\mu - k\sigma \leq X \leq \mu  + k\sigma)$, donde X tiene distribución N($\mu,\sigma$). La probabilidad anterior se puede expresar en t términos de la función $\Phi$ escribiendo}
\vspace{0,3cm}

\[P(\mu-k\sigma \leq  X \leq \mu + k\sigma) = \left(-k\leq \frac{X-\mu}{\sigma}\leq k\right) = \Phi(k) - \Phi(-k) = 2\Phi(k)-1\]

{Nótese que la probabilidad anterior es independiente de $\mu$ y $\sigma$. En palabras, la probabilidad de que una variable aleatoria con distribución N($\mu,\sigma^2$) tome valores dentro de k desviaciones estándar del valor esperado depende sólo de k. }

\begin{center}
    \bf Ejemplos p. 246-249
\end{center}
\vspace{1cm}

\section{\bf Funcion de una variable aleatoria}
\vspace{0.5cm}

{Supongamos que el radio X de la entrada de un tubo muy bien calibrado se considera como una variable aleatoria continua con fdp f. Sea A = $\pi X^2$ el área de la sección de la entrada; entonces es evidente que, puesto que el valor de X es el resultado de un experimento aleatorio, también lo es el valor de A. Es decir, A es una variable aleatoria (continua), y
podríamos obtener su fdp, digamos g. Esperaríamos que, puesto que A es una función de X, la fdp g se puede derivar de alguna manera conociendo la fdp f. En este capítulo trataremos problemas de esta naturaleza. Antes de familiarizarnos con algunas técnicas específicas necesarias, formularemos los conceptos anteriores con mayor precisión.}

\subsection{Eventos equivalentes}

{Sean $\epsilon$ un experimento, S un espacio muestral asociado con $\epsilon$ y X una variable aleatoria definida en S; supongamos que y = H(x) es una funcion real de x. Entonces, Y = H(X) es una variable aleatoria puesto que para cada $s \in S$ se determina un valor de Y, digamos y = H[X(s)]. Como antes llamamos $R_x$ al espacio del intervalo de X, el conjunto de posibles valores de la funcion X; de igual modo, definimos $R_y$ {\bf el espacio del intervalo de la variable aleatoria Y}, el conjunto de los valores posibles de Y. \\\\}

{\bf Definicion.} {Sea C un evento (subconjunto) asociado con el recorrido de Y, $R_y$ como se describió anteriormente. Definase B $\subset \ R_x$, como sigue: \\}

\[B = \{x \in R_x:H(x) \in C\}\]

{En palabras, B es el conjunto de los valores de X tales que $H(x) \in C.$ Si B y C estan relacionados de esta manera los llamaremos {eventos equivalentes}}.
\vspace{0.5cm}

{\bf Observaciones.}
\begin{itemize}
    \item [a)] Como dijimos antes, la interpretacion informal de lo anterior es que B y C son eventos equivalentes si y solo si B y C ocurren juntas.
    \item [b)] Si A es un evento asociado con S, B un evento asociado con $R_x$, C es un evento asociado con $R_y$ y ademas C es equivalente a B, entonces A es equivalente a C.
    \item [c)] Nuevamente es importante darse cuenta de que cuando hablemos de eventos equivalentes, estos eventos estan asociados con espacios muestrales diferentes.
\end{itemize}

\begin{center}
    \bf Ejemplo p. 106-107
\end{center}


\newpage

{\bf Definicion.} {Sean X una variable aleatoria definida en el espacio muestral S, $R_x$, el recorrido de X y H una función real, y consideremos la variable aleatoria Y = H(X) con recorrido $R_y$. Para cualquier evento $C \subset R_y$, definimos P(C) como sigue: }

\[P(C) = P[{x\in R_x : H(x) \in C}] = P[\{s\in S : H(X(s)) \in C\}] \]

{En palabras, la probabilidad de un evento asociado con el recorrido de Y está definida como la probabilidad del evento equivalente (en terminos de X). La definición anterior hará posible calcular las probabilidades relacionadas con eventos con Y si conocemos la distribución de probabilidades de X y podemos determinar el evento equivalente en cuestión.}

\begin{center}
    \bf Ejemplo p 107-108
\end{center}
\vspace{1cm}
\subsection{Variables aleatorias discretas}
\vspace{1cm}

{{\bf Caso 1.} Si X es una variable aleatoria discreta, se deduce de inmediato que Y tambien lo es. Porque supóngase que los valores posibles de X se pueden enumerar como $x_1,x_2,...,x_n,...$. Con seguridad, los valores posibles de Y se pueden enumerar como $y_1 = H(x_1), y_2=H(x_2),...$ . (Algunos de los valores anteriores de Y pueden ser iguales, pero esto ciertamente no impide el hecho de que esos valores puedan enumerarse.) }
\vspace{0,3cm}

\begin{center}
    \bf Ejemplos p 109-110
\end{center}
\vspace{0,3cm}

{El procedimiento general para situaciones como la descrita en el ejemplo anterior es el que sigue: representemos con $x_i_1,x_i_2,...$, los
valores de X que tienen la propiedad H($x_i_j) = y_i$ para toda j. Luego}

\[q(y_j) = P(Y = y_i) = p(x_i_1) + p(x_i_2) + ... \]

{En palabras, para calcular la probabilidad del evento \{Y = $y_j$\}, encuentre el evento equivalente en términos de X (en el recorrido $R_x$) y luego sume todas las probabilidades correspondientes}.
\vspace{0,3cm}

\begin{center}
    \bf Ejemplo p 110
\end{center}
\vspace{1cm}

{{\bf Caso 2. } Puede suceder que X sea una variable aleatoria continua, mientras que Y sea discreta. Por ejemplo, supongamos que S puede tomar todos los valores reales, mientras que se define que Y sea 1 si $x \geq 0$ y que Y = -1 si $x < 0$. Para obtener la distribución de probabilidades de Y, determinemos simplemente el evento equivalente (en el recorrido $R_x$) que corresponde a los diferentes valores de Y. En el caso anterior, Y = 1 si y sólo si $x \geq 0$ mientras que Y = -1 si y sólo si $x < 0$. Por lo tanto, P(Y = 1) = P(X $>$ 0), mientras que P(Y = - 1) = P(X $<$ 0). Si se conoce la fdp de S pueden calcularse estas probabilidades. \\ \\ En el caso general, si {Y = yi} es equivalente a un evento, digamos A, en el recorrido de X entonces, }

\[q(y_i) = P(Y =y_i) = \int_A f(x)dx.\]

\newpage

\subsection{Variables aleatorias continuas}
\vspace{1cm}

{El caso más importante (y el que se encuentra con mayor frecuencia) aparece cuando X es una variable aleatoria continua con fdp f y H es una función continua. Por tanto, Y = H(X) es una variable aleatoria continua y nuestro propósito será obtener su fdp, digamos g.\\}

{\bf Procedimiento general}
\begin{itemize}
    \item [a)]  Obtenga G, la fda de Y, donde G(y) = P(Y $\leq$ y), después de encontrar el evento A (en el recorrido de X) que equivale al evento \{Y $\leq y$\}.
    
    \item [b)] Diferencie G(y) respecto a y para obtener g(y)
    
    \item [c)] Determine estos valores de y en el recorrido de Y para los cuales g(y) $>$ 0.
\end{itemize}

\vspace{0,3cm}

\begin{center}
    \bf Ejemplo y otro metodo p 111-114
\end{center}
\vspace{1cm}

{\bf Teorema.} {Sea X una variable aleatoria continua con fdp f, donde f(x) $> 0$ para a $<$ x $<$ b. Supóngase que y = H(x) sea una función de x estrictamente monótona (creciente o decreciente). Supungase que esta función es derivable (y, por tanto, continua) para toda x. Entonces, la variable aleatoria Y definida como Y = H(X) tiene una fdp g dada por }

\[g(y) = f(x) \left|\frac{dx}{dy}\right|\]

{donde x se expresa en términos de y. Si H es creciente, entonces g es distinta de cero para los valores de y que satisfacen H(a) $<$ y $<$ H(b).
Si H es decreciente, entonces g es distinta de cero para los valores de y que satisfacen H(b) $<$ y $<$ H(a).}

\begin{center}
{\bf Leer demostracion 114-115\\\\}
{Ejemplos 115-116}
\end{center}
\vspace{1cm}

\subsection{Esperanza de una funcion de una variable aleatoria}
\vspace{1cm}

{\bf Definicion.} {Sea X una variable aleatoria y sea Y = H(X).}
\begin{itemize}
    \item [a)] Si Y es una variable aleatoria discreta con valores posibles $y_1,y_2,...$ y si q($y_i$) = P(Y = $y_i$), definimos \[E(Y) = \sum_{i=1}^\infty y_iq(y_i)\]
    
    \item [b)]  Si Y es una variable aleatoria continua con fdp g, definimos \[E(Y) = \int_{-\infty}^\infty yq(y)dy\]
\end{itemize}
\vspace{0,5cm}

{Una “desventaja” de aplicar la definición anterior para obtener E(Y) es que la distribución de probabilidades de Y es necesaria. podemos
obtener E(Y) sólo a partir del conocimiento de la distribución de probabilidades de X con el siguiente teorema.}
\newpage

{\bf Teorema} {Sea X una variable aleatoria y sea Y = H(X).}
\begin{itemize}
    \item [a)] Si X es una variable aleatoria discreta y $p(x_i) = P(X = x_i), tenemos$ 
    \[E(Y) = E(H(X)) = \sum_{i=1}^\infty H(x_i)p(x_i)\]
    
    \item [b)] Si X es una variable aleatoria continua con fdp f, tenemos
    \[E(Y) = E(H(X)) = \int_{-\infty}^\infty H(x)f(x)dx\]
    
    \item [c)] Si X una variable aleatoria continua con fdp f y Y es discreta tenemos:
    \[E(Y) = \sum_{y\in R_y} yP_y(y)= \sum_{B\in im(H^{-1})} \int_B H(X)f_x(X)dx \]
\end{itemize}
\begin{center}
    \bf Demostracion p 163
\end{center}

{Este teorema hace mucho más sencilla la evaluacion de E(Y), porque quiere decir que no necesitamos encontrar la distribucion de probabilidades de Y para evaluar E(Y). Es suficiente conocer la distribucion de probabilidades de X. }
\vspace{0,3cm}
\begin{center}
    \bf Ejemplos 163-166
\end{center}

\vspace{2cm}

\section{Una observación}
\vspace{1cm}

{Hemos señalado varias veces que en alguna etapa del desarrollo de nuestro modelo probabilístico deben asignarse algunas probabilidades a los resultados sobre la base de alguna evidencia experimental (como es la frecuencia relativa, por ejemplo) o algunas otras consideraciones, tales como experiencias pasadas con los fenómenos estudiados. El interrogante siguiente se le podría presentar al estudiante: ¿por qué no podríamos obtener todas las probabilidades en las cuales estamos interesados por un medio no deductivo? La respuesta es que muchos eventos cuyas probabilidades deseamos conocer, son tan complicados que nuestro conocimiento intuitivo es insuficiente. Lo que aquí se destaca es que los diversos métodos para calcular probabilidades que hemos derivado (y los que estudiaremos posteriormente) són de mucha importancia, puesto que con ellos podcmos calcular las probabilidadcs asociadas con eventos más complicados, lo cual sería dificil de obtener con medios intuitivos o empíricos. }

\vspace{1cm}
\begin{center}
    \bf Ejemplo pág 98
\end{center}

























\end{document}